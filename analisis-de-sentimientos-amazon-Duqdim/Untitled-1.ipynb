{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Empty DataFrame\n",
       " Columns: [msg, lbl]\n",
       " Index: [],\n",
       "                                                     msg  lbl\n",
       " 2                           Good case, Excellent value.  1.0\n",
       " 5                                Great for the jawbone.  1.0\n",
       " 11                                    The mic is great.  1.0\n",
       " 17          If you are Razr owner...you must have this!  1.0\n",
       " 24                      And the sound quality is great.  1.0\n",
       " ...                                                 ...  ...\n",
       " 2742                                 Excellent product.  1.0\n",
       " 2748  It is the best charger I have seen on the mark...  1.0\n",
       " 2749                                  SWEETEST PHONE!!!  1.0\n",
       " 2750             :-)Oh, the charger seems to work fine.  1.0\n",
       " 2751  It fits so securely that the ear hook does not...  1.0\n",
       " \n",
       " [500 rows x 2 columns],\n",
       " 0        I try not to adjust the volume setting to avoi...\n",
       " 3              I thought Motorola made reliable products!.\n",
       " 4                               Battery for Motorola Razr.\n",
       " 6        When I got this item it was larger than I thou...\n",
       " 7        (I looked for one that specifically said DCU-6...\n",
       "                                ...                        \n",
       " 14604          The screen on my phone said \"Not Charging\".\n",
       " 14605     This is my 4th Samsung cell phone with T-Mobile.\n",
       " 14606                                       great company.\n",
       " 14607    The \"call\" and \"hang-up\" keys are now properly...\n",
       " 14608                Hopefully the Kyocera will be better!\n",
       " Name: msg, Length: 13609, dtype: object,\n",
       " 0       NaN\n",
       " 3       NaN\n",
       " 4       NaN\n",
       " 6       NaN\n",
       " 7       NaN\n",
       "          ..\n",
       " 14604   NaN\n",
       " 14605   NaN\n",
       " 14606   NaN\n",
       " 14607   NaN\n",
       " 14608   NaN\n",
       " Name: lbl, Length: 13609, dtype: float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pregunta_01():\n",
    "    \"\"\"\n",
    "    Carga de datos.\n",
    "    -------------------------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "\n",
    "    # Lea el archivo `amazon_cells_labelled.tsv` y cree un DataFrame usando pandas.\n",
    "    # Etiquete la primera columna como `msg` y la segunda como `lbl`. Esta función\n",
    "    # retorna el dataframe con las dos columnas.\n",
    "    tabla = pd.read_csv(\"amazon_cells_labelled.tsv\",\n",
    "        sep='\\t',\n",
    "        header=None,\n",
    "        names=['msg','lbl'],\n",
    "    )\n",
    "    df=pd.DataFrame(tabla)\n",
    "\n",
    "    # Separe los grupos de mensajes etiquetados y no etiquetados.\n",
    "    df_tagged = df[(df[\"lbl\"]>=0)]\n",
    "    df_untagged = df[df[\"lbl\"].isnull()]\n",
    "\n",
    "    x_tagged = df_tagged[df_tagged[\"msg\"] ==0.0];x_tagged\n",
    "    y_tagged = df_tagged[df_tagged[\"lbl\"] ==1.0];y_tagged\n",
    "\n",
    "    x_untagged = df_untagged[\"msg\"]\n",
    "    y_untagged = df_untagged[\"lbl\"]\n",
    "\n",
    "    # Retorne los grupos de mensajes\n",
    "    return (x_tagged, y_tagged, x_untagged, y_untagged)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [0, 500]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CASARG~1\\AppData\\Local\\Temp/ipykernel_6488/417850891.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# Retorne `X_train`, `X_test`, `y_train` y `y_test`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mpregunta_02\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\CASARG~1\\AppData\\Local\\Temp/ipykernel_6488/417850891.py\u001b[0m in \u001b[0;36mpregunta_02\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Divida los datos de entrenamiento y prueba. La semilla del generador de números\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# aleatorios es 12345. Use el 10% de patrones para la muestra de prueba.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_tagged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tagged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12345\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# Retorne `X_train`, `X_test`, `y_train` y `y_test`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Casa RG4L\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2170\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one array required as input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2172\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Casa RG4L\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    354\u001b[0m     \"\"\"\n\u001b[0;32m    355\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Casa RG4L\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    320\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [0, 500]"
     ]
    }
   ],
   "source": [
    "def pregunta_02():\n",
    "    \"\"\"\n",
    "    Preparación de los conjuntos de datos.\n",
    "    -------------------------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "\n",
    "    # Importe train_test_split\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # Cargue los datos generados en la pregunta 01.\n",
    "    x_tagged, y_tagged, x_untagged, y_untagged = pregunta_01()\n",
    "\n",
    "    # Divida los datos de entrenamiento y prueba. La semilla del generador de números\n",
    "    # aleatorios es 12345. Use el 10% de patrones para la muestra de prueba.\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_tagged, y_tagged, test_size=0.1,random_state=12345)\n",
    "\n",
    "    # Retorne `X_train`, `X_test`, `y_train` y `y_test`\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pregunta_03():\n",
    "    \"\"\"\n",
    "    Construcción de un analizador de palabras\n",
    "    -------------------------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "    # Importe el stemmer de Porter\n",
    "    # Importe CountVectorizer\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from nltk.stem.porter  import PorterStemmer\n",
    "\n",
    "    # Cree un stemeer que use el algoritmo de Porter.\n",
    "    stemmer = PorterStemmer()\n",
    "    vectorr= CountVectorizer(analyzer=\"word\",token_pattern=r\"(?u)\\b[a-zA-z][a-zA-z]+\\b\", lowercase=True)\n",
    "    # Cree una instancia del analizador de palabras (build_analyzer)\n",
    "    analyzer = vectorr.build_analyzer()\n",
    "\n",
    "    # Retorne el analizador de palabras\n",
    "    return lambda x: (stemmer.stem(w) for w in analyzer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pregunta_04():\n",
    "    \"\"\"\n",
    "    Especificación del pipeline y entrenamiento\n",
    "    -------------------------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "\n",
    "    # Importe CountVetorizer\n",
    "    # Importe GridSearchCV\n",
    "    # Importe Pipeline\n",
    "    # Importe BernoulliNB\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "    # Cargue las variables.\n",
    "    x_train, _, y_train, _ = pregunta_02()\n",
    "\n",
    "    # Obtenga el analizador de la pregunta 3.\n",
    "    analyzer = pregunta_03()\n",
    "\n",
    "    # Cree una instancia de CountVectorizer que use el analizador de palabras\n",
    "    # de la pregunta 3. Esta instancia debe retornar una matriz binaria. El\n",
    "    # límite superior para la frecuencia de palabras es del 100% y un límite\n",
    "    # inferior de 5 palabras. Solo deben analizarse palabras conformadas por\n",
    "    # letras.\n",
    "    countVectorizer = countVectorizer(analyzer=analyzer(),lowercase=True,stop_words=\"english\",token_pattern=r\"(?u)\\b[a-zA-Z][a-zA-Z]+\\b\",binary=False,max_df=1.0,min_df=5)\n",
    "\n",
    "    # Cree un pipeline que contenga el CountVectorizer y el modelo de BernoulliNB.\n",
    "    pipeline = pipeline(steps=[(\"countvectorizer\", countVectorizer),\n",
    "            (\"BernoulliNB\", BernoulliNB()),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Defina un diccionario de parámetros para el GridSearchCV. Se deben\n",
    "    # considerar 10 valores entre 0.1 y 1.0 para el parámetro alpha de\n",
    "    # BernoulliNB.\n",
    "    param_grid = {\"BernoulliNB_alpha\": np.arange(0.1, 1.1, 10)}\n",
    "\n",
    "    # Defina una instancia de GridSearchCV con el pipeline y el diccionario de\n",
    "    # parámetros. Use cv = 5, y \"accuracy\" como métrica de evaluación\n",
    "    gridSearchCV = GridSearchCV(estimator=pipeline,param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring=\"accuracy\",\n",
    "        refit=True,\n",
    "        return_train_score=True,\n",
    "    )\n",
    "\n",
    "    # Búsque la mejor combinación de regresores\n",
    "    gridSearchCV.fit(x_train, y_train)\n",
    "\n",
    "    # Retorne el mejor modelo\n",
    "    return gridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pregunta_05():\n",
    "    \"\"\"\n",
    "    Evaluación del modelo\n",
    "    -------------------------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "\n",
    "    # Importe confusion_matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    # Obtenga el pipeline de la pregunta 3.\n",
    "    gridSearchCV = pregunta_04()\n",
    "\n",
    "    # Cargue las variables.\n",
    "    X_train, X_test, y_train, y_test = pregunta_02()\n",
    "\n",
    "    # Evalúe el pipeline con los datos de entrenamiento usando la matriz de confusion.\n",
    "    cm_train = confusion_matrix(\n",
    "        y_true=y_train,\n",
    "        y_pred=gridSearchCV.predict(X_train),\n",
    "    )\n",
    "\n",
    "    cm_test = confusion_matrix(\n",
    "        y_true=y_test,\n",
    "        y_pred=gridSearchCV.predict(X_test),\n",
    "    )\n",
    "\n",
    "    # Retorne la matriz de confusion de entrenamiento y prueba\n",
    "    return cm_train, cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pregunta_06():\n",
    "    \"\"\"\n",
    "    Pronóstico\n",
    "    -------------------------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "\n",
    "    # Obtenga el pipeline de la pregunta 3.\n",
    "    gridSearchCV = pregunta_04()\n",
    "\n",
    "    # Cargue los datos generados en la pregunta 01.\n",
    "    x_tagged,y_tagged, x_untagged,y_untagged = pregunta_01()\n",
    "\n",
    "    # pronostique la polaridad del sentimiento para los datos\n",
    "    # no etiquetados\n",
    "    y_untagged_pred = gridSearchCV.predict(x_untagged)\n",
    "\n",
    "    # Retorne el vector de predicciones\n",
    "    return y_untagged_pred"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "065dbd92cb0decb42a7bd5bfdc73d4338e2c75da82dbd2efe8d1a8bed6ec3d33"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
